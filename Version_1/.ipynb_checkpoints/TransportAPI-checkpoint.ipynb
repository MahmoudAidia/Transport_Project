{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8efeaebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seatbel Model is being loaded!\n",
      "Drowsiness Model is being loaded!\n",
      "Distraction Model is being loaded!\n",
      "Model loaded!\n",
      "Model loaded!\n",
      "Model loaded!\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import cv2\n",
    "import base64\n",
    "import numpy as np\n",
    "import io\n",
    "from PIL import Image\n",
    "import keras\n",
    "from keras import backend as k\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from flask import request, jsonify, Flask\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from mtcnn import MTCNN\n",
    "\n",
    "\n",
    "# App\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "# function to load the models\n",
    "def load_model_fn(path):\n",
    "    model = load_model(path)\n",
    "    print('Model loaded!')\n",
    "    return model\n",
    "\n",
    "\n",
    "# function to resize our image\n",
    "def preprocess_image(image, target_size):\n",
    "    if image.mode != 'RGB':\n",
    "        image = image.convert('RGB')\n",
    "    image = image.resize(target_size)\n",
    "    image = np.array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    return image\n",
    "\n",
    "\n",
    "# Crop Eye Funtion:\n",
    "def crop_eye(image_array, eye_cas_path=\"haar_cascade_files/haarcascade_eye.xml\"):\n",
    "    gray = cv2.cvtColor(image_array, cv2.COLOR_BGR2GRAY)\n",
    "    eye_cascade = cv2.CascadeClassifier(eye_cas_path)\n",
    "    eyes = eye_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    if len(eyes) > 0:\n",
    "        (x, y, w, h) = eyes[0]\n",
    "        cropped_eye = image_array[y:y+h, x:x+w]\n",
    "        resized_eye = cv2.resize(cropped_eye, (145, 145))\n",
    "        normalized_eye = resized_eye / 255.0\n",
    "        input_data = normalized_eye.reshape(1, 145, 145, 3)\n",
    "        return input_data\n",
    "    \n",
    "# Crop Face Funtion:\n",
    "def crop_face(image_array, face_cas_path=\"haar_cascade_files/haarcascade_frontalface_default.xml\"):\n",
    "    gray = cv2.cvtColor(image_array, cv2.COLOR_BGR2GRAY)\n",
    "    eye_cascade = cv2.CascadeClassifier(face_cas_path)\n",
    "    eyes = eye_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    if len(eyes) > 0:\n",
    "        (x, y, w, h) = eyes[0]\n",
    "        cropped_eye = image_array[y:y+h, x:x+w]\n",
    "        resized_eye = cv2.resize(cropped_eye, (145, 145))\n",
    "        normalized_eye = resized_eye / 255.0\n",
    "        input_data = normalized_eye.reshape(1, 145, 145, 3)\n",
    "        return input_data\n",
    "    \n",
    "    \n",
    "# Map face Prediction\n",
    "def map_face_prediction(prediction):\n",
    "    prediction = np.array(prediction, dtype=np.float32)\n",
    "    # Find the index of the largest value\n",
    "    index_of_largest_value = np.argmax(prediction)\n",
    "    mapping_list = ['yawn', 'no_yawn', 'Closed', 'Open']\n",
    "    mapped_value = mapping_list[index_of_largest_value]\n",
    "    # Print the result\n",
    "    result_1 = f\"{mapped_value}\"\n",
    "    return result_1\n",
    "\n",
    "\n",
    "# Map eye Prediction\n",
    "def map_eye_prediction(prediction):\n",
    "    input_array = np.array(prediction, dtype=np.float32)\n",
    "    mapping_list = ['yawn', 'no_yawn', 'Closed', 'Open']\n",
    "    index_of_largest_value = np.argmax(input_array)\n",
    "    largest_value = input_array[0, index_of_largest_value]\n",
    "    mapped_value = mapping_list[index_of_largest_value]\n",
    "    result_2 = f\"{mapped_value}\"\n",
    "    return result_2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Loading the models !!!\n",
    "print('Seatbel Model is being loaded!')\n",
    "print('Drowsiness Model is being loaded!')\n",
    "print('Distraction Model is being loaded!')\n",
    "\n",
    "seatbelt_model = load_model_fn('./models/seatbelt/seatbelt_Model_2.h5')\n",
    "distraction_CNN_model = load_model_fn('./models/distracted_driver/CNNModel with Data Augmentation.h5')\n",
    "drowsiness_model = load_model_fn('./models/driver_drowsiness/drowiness_new6.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a23c847c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 1- Seatbelt API\n",
    "@app.route('/seatbelt', methods=['POST'])\n",
    "def predict():\n",
    "    try:\n",
    "        message = request.get_json(force=True)\n",
    "        encoded = message['image']\n",
    "        decoded = base64.b64decode(encoded)\n",
    "        image = Image.open(io.BytesIO(decoded))\n",
    "    except:\n",
    "        result = 'Unable to decode Image'\n",
    "        return jsonify(result)\n",
    "        \n",
    "    try:\n",
    "        processed_image = preprocess_image(image, target_size=(200, 200))\n",
    "        prediction = seatbelt_model.predict(processed_image).tolist()\n",
    "    except:\n",
    "        result = 'The model could not predict the image'\n",
    "        return jsonify(result)\n",
    "        \n",
    "    response = {\n",
    "        'prediction': {\n",
    "            'seatbelt': prediction[0][0],\n",
    "            'no seatbelt': prediction[0][1]\n",
    "        }\n",
    "    }\n",
    "    # Extract the label with the highest prediction value\n",
    "    result = max(response['prediction'], key=response['prediction'].get)\n",
    "    return jsonify(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "194deb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2- #Drowsiness API\n",
    "@app.route('/drowsiness', methods=['POST'])\n",
    "def predict_drowsiness():\n",
    "    try:\n",
    "        message = request.get_json(force=True)\n",
    "        encoded = message['image']\n",
    "        decoded = base64.b64decode(encoded)\n",
    "        image = Image.open(io.BytesIO(decoded))\n",
    "    except:\n",
    "        result = 'Unable to decode Image'\n",
    "        return jsonify(result)\n",
    "    \n",
    "    try:\n",
    "        processed_face = crop_face(image_array=image_array)\n",
    "        prediction_face = drowsiness_model.predict(processed_face).tolist()\n",
    "        face_result = map_face_prediction(prediction_face)\n",
    "    except:\n",
    "        face_result = 'The model could not crop the face'\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        processed_eye = crop_eye(image_array=image_array)\n",
    "        prediction_eye = drowsiness_model.predict(processed_eye).tolist()\n",
    "        eye_result = map_eye_prediction(prediction_eye)\n",
    "    except:\n",
    "        eye_result = 'The model could not crop the eye'\n",
    "        \n",
    "    response = {\n",
    "        \"Face_Prediction\": face_result,\n",
    "        \"Eye_Prediction\": eye_result\n",
    "    }\n",
    "    \n",
    "\n",
    "    return jsonify(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de5e6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 149ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [17/Sep/2023 13:36:51] \"POST /distraction HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 45ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [17/Sep/2023 13:37:17] \"POST /distraction HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 3- Distraction API\n",
    "@app.route('/distraction', methods=['POST'])\n",
    "def predict_driver_distraction():\n",
    "    try:\n",
    "        message = request.get_json(force=True)\n",
    "        encoded = message['image']\n",
    "        decoded = base64.b64decode(encoded)\n",
    "        image = Image.open(io.BytesIO(decoded))\n",
    "    except:\n",
    "        result = 'Unable to decode message'\n",
    "        return jsonify(result)\n",
    "    \n",
    "    processed_image = preprocess_image(image, target_size=(224, 224))\n",
    "    \n",
    "    try:\n",
    "        prediction = distraction_CNN_model.predict(processed_image).tolist()\n",
    "    except:\n",
    "        result = 'The model could not predict the Image'\n",
    "        return jsonify(result)\n",
    "    \n",
    "    label = ['normal driving',\n",
    "             'texting - right',\n",
    "             'talking on the phone - right',\n",
    "             'texting - left',\n",
    "             'talking on the phone - left',\n",
    "             'operating the radio',\n",
    "             'drinking',\n",
    "             'reaching behind',\n",
    "             'hair and makeup',\n",
    "             'talking to passenger']\n",
    "    max_index = np.argmax(prediction)\n",
    "    result = label[max_index]\n",
    "\n",
    "    return jsonify(result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba93fde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec49e85f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
