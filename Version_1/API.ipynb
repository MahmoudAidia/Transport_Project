{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50779769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seatbel Model is being loaded!\n",
      "Drowsiness Model is being loaded!\n",
      "Distraction Model is being loaded!\n",
      "Model loaded!\n",
      "Model loaded!\n",
      "Model loaded!\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 196ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [18/Sep/2023 19:48:26] \"POST /drowsiness HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [18/Sep/2023 19:50:35] \"POST /drowsiness HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [18/Sep/2023 19:51:36] \"POST /drowsiness HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [18/Sep/2023 19:52:25] \"POST /drowsiness HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [18/Sep/2023 19:57:53] \"POST /drowsiness HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [18/Sep/2023 19:58:21] \"POST /drowsiness HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [18/Sep/2023 19:58:54] \"POST /drowsiness HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [18/Sep/2023 20:03:45] \"POST /drowsiness HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [18/Sep/2023 20:05:09] \"POST /drowsiness HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [18/Sep/2023 20:05:49] \"POST /drowsiness HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [18/Sep/2023 20:06:17] \"POST /drowsiness HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [18/Sep/2023 20:06:54] \"POST /drowsiness HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import cv2\n",
    "import base64\n",
    "import numpy as np\n",
    "import io\n",
    "from PIL import Image\n",
    "import keras\n",
    "from keras import backend as k\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from flask import request, jsonify, Flask\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from facenet_pytorch import MTCNN\n",
    "\n",
    "\n",
    "# App\n",
    "app = Flask(__name__)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# function to load the models\n",
    "def load_model_fn(path):\n",
    "    model = load_model(path)\n",
    "    print('Model loaded!')\n",
    "    return model\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# function to resize our image\n",
    "def preprocess_image(image, target_size):\n",
    "    if image.mode != 'RGB':\n",
    "        image = image.convert('RGB')\n",
    "    image = image.resize(target_size)\n",
    "    image = np.array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    return image\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Initialize MTCNN\n",
    "mtcnn = MTCNN()\n",
    "# Crop Face Funtion:\n",
    "def crop_face(image_array):\n",
    "    IMG_SIZE = 145\n",
    "    \n",
    "    # Use MTCNN to detect faces\n",
    "    boxes, _ = mtcnn.detect(image_array)\n",
    "    \n",
    "    # Check if a face was detected\n",
    "    if boxes is not None:\n",
    "        for box in boxes:\n",
    "            x, y, w, h = box\n",
    "            \n",
    "            # Crop and resize the image\n",
    "            roi_color = image_array[int(y):int(h), int(x):int(w)]\n",
    "            try:\n",
    "                resized_array = cv2.resize(roi_color, (IMG_SIZE, IMG_SIZE))\n",
    "            except:\n",
    "                return None\n",
    "            \n",
    "            return resized_array\n",
    "\n",
    "    return None  # Return None if no faces are detected\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Crop Eye Funtion:\n",
    "def crop_eye(image_array):\n",
    "    # Initialize MTCNN\n",
    "    mtcnn = MTCNN(keep_all=True)\n",
    "    IMG_SIZE = 145\n",
    "    \n",
    "    # Use MTCNN to detect faces and facial landmarks\n",
    "    boxes, probs, landmarks = mtcnn.detect(image_array, landmarks=True)\n",
    "    \n",
    "    # Check if an eye was detected\n",
    "    if boxes is not None:\n",
    "        for landmark in landmarks:\n",
    "            # Get the landmarks for the eyes\n",
    "            left_eye = landmark[0]\n",
    "            right_eye = landmark[1]\n",
    "            \n",
    "            # Crop and resize the image around the left eye\n",
    "            roi_color = image_array[int(left_eye[1]-IMG_SIZE/3):int(left_eye[1]+IMG_SIZE/5), int(left_eye[0]-IMG_SIZE/4):int(left_eye[0]+IMG_SIZE/5)]\n",
    "            if roi_color.size != 0:  # Check if the ROI is not empty\n",
    "                try:\n",
    "                    resized_array = cv2.resize(roi_color, (IMG_SIZE, IMG_SIZE))\n",
    "                except:\n",
    "                    return None\n",
    "                \n",
    "                return resized_array\n",
    "            \n",
    "    return None\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Loading the models !!!\n",
    "print('Seatbel Model is being loaded!')\n",
    "print('Drowsiness Model is being loaded!')\n",
    "print('Distraction Model is being loaded!')\n",
    "\n",
    "seatbelt_model = load_model_fn('./seatbelt_Model_2.h5')\n",
    "distraction_CNN_model = load_model_fn('./Distracted_Driver_Data_Augmentation.h5')\n",
    "drowsiness_model = load_model_fn('./drowiness_new6.h5')\n",
    "\n",
    "# ###################################################################################################\n",
    "\n",
    "# 1- Seatbelt API\n",
    "@app.route('/seatbelt', methods=['POST'])\n",
    "def predict():\n",
    "    try:\n",
    "        message = request.get_json(force=True)\n",
    "        encoded = message['image']\n",
    "        decoded = base64.b64decode(encoded)\n",
    "        image = Image.open(io.BytesIO(decoded))\n",
    "    except:\n",
    "        result = 'Unable to decode Image'\n",
    "        return jsonify(result)\n",
    "        \n",
    "    try:\n",
    "        processed_image = preprocess_image(image, target_size=(200, 200))\n",
    "        prediction = seatbelt_model.predict(processed_image).tolist()\n",
    "        print(prediction)\n",
    "    except:\n",
    "        result = 'The model could not predict the image'\n",
    "        return jsonify(result)\n",
    "    \n",
    "    \n",
    "     \n",
    "    largest_value = max(prediction[0])\n",
    "    print(largest_value)\n",
    "    if largest_value > .60 :       \n",
    "        response = {\n",
    "            'prediction': {\n",
    "                'seatbelt': prediction[0][0],\n",
    "                'no seatbelt': prediction[0][1]\n",
    "            }\n",
    "        }\n",
    "        result = max(response['prediction'], key=response['prediction'].get)\n",
    "    elif largest_value < .60:\n",
    "        result = 'Unknown'\n",
    "    print(result)\n",
    "    # Extract the label with the highest prediction value\n",
    "    return jsonify(result)\n",
    "\n",
    "# ###################################################################################################\n",
    "\n",
    "# 2- #Drowsiness API\n",
    "@app.route('/drowsiness', methods=['POST'])\n",
    "def predict_drowsiness():\n",
    "    message = request.get_json(force=True)\n",
    "    encoded = message['image']\n",
    "    decoded = base64.b64decode(encoded)\n",
    "    image = Image.open(io.BytesIO(decoded))\n",
    "    image_array = np.array(image)\n",
    "    \n",
    "    # Apply the preprocessing function\n",
    "    face_image = crop_face(image_array=image_array)\n",
    "    \n",
    "    # Check if a face was detected\n",
    "\n",
    "        \n",
    "    if face_image is not None:\n",
    "        # Reshape and normalize the image\n",
    "        face_data = face_image.reshape(1, 145, 145, 3) / 255.0\n",
    "    \n",
    "        # Make prediction\n",
    "        prediction_face = drowsiness_model.predict(face_data).tolist()\n",
    "        largest_value = max(prediction_face[0])\n",
    "        mapping_list = ['yawn', 'no_yawn', 'Closed', 'Open']\n",
    "        \n",
    "        if largest_value > .60:\n",
    "            index_of_largest_value = np.argmax(prediction_face)\n",
    "            \n",
    "            if index_of_largest_value >1:\n",
    "                result1 = 'Unknown'\n",
    "            elif index_of_largest_value <= 1:\n",
    "                result1 = mapping_list[index_of_largest_value]\n",
    "        elif largest_value < .60:\n",
    "            result1 = 'Unknown'\n",
    "    else:\n",
    "        result1 = \"No faces detected in the image.\"\n",
    "    \n",
    "    # ------------------------------------------------------------\n",
    "    \n",
    "    # Apply the preprocessing function\n",
    "    eye_image = crop_eye(image_array=image_array)\n",
    "    \n",
    "    # Check if a face was detected\n",
    "    if eye_image is not None:\n",
    "        \n",
    "        # Reshape and normalize the image\n",
    "        eye_data = eye_image.reshape(1, 145, 145, 3) / 255.0\n",
    "    \n",
    "        # Make prediction\n",
    "        prediction_eye = drowsiness_model.predict(eye_data).tolist()\n",
    "        largest_value = max(prediction_eye[0])\n",
    "        mapping_list = ['yawn', 'no_yawn', 'Closed', 'Open']\n",
    "        \n",
    "        \n",
    "    \n",
    "        # Map prediction to output\n",
    "        mapping_list = ['yawn', 'no_yawn', 'Closed', 'Open']\n",
    "        if largest_value > .60:\n",
    "            index_of_largest_value = np.argmax(prediction_face)\n",
    "            \n",
    "            if index_of_largest_value < 2:\n",
    "                result2 = 'Unknown'\n",
    "            elif index_of_largest_value >=2:\n",
    "                result2 = mapping_list[index_of_largest_value]\n",
    "        elif largest_value < .60:\n",
    "            result2 = 'Unknown'\n",
    "    \n",
    "    else:\n",
    "        result2 = \"No Eyes detected in the image.\"\n",
    "\n",
    "       \n",
    "    response = {\n",
    "        \"Face_Prediction\": result1,\n",
    "        \"Eye_Prediction\": result2\n",
    "    }\n",
    "    \n",
    "\n",
    "    return jsonify(response)\n",
    "\n",
    "# ###################################################################################################\n",
    "\n",
    "# 3- Distraction API\n",
    "@app.route('/distraction', methods=['POST'])\n",
    "def predict_driver_distraction():\n",
    "    try:\n",
    "        message = request.get_json(force=True)\n",
    "        encoded = message['image']\n",
    "        decoded = base64.b64decode(encoded)\n",
    "        image = Image.open(io.BytesIO(decoded))\n",
    "    except:\n",
    "        result = 'Unable to decode message'\n",
    "        return jsonify(result)\n",
    "    \n",
    "    processed_image = preprocess_image(image, target_size=(224, 224))\n",
    "    \n",
    "    try:\n",
    "        prediction = distraction_CNN_model.predict(processed_image).tolist()\n",
    "        print(prediction)\n",
    "    except:\n",
    "        result = 'The model could not predict the Image'\n",
    "        return jsonify(result)\n",
    "    \n",
    "    label = ['normal driving',\n",
    "             'texting - right',\n",
    "             'talking on the phone - right',\n",
    "             'texting - left',\n",
    "             'talking on the phone - left',\n",
    "             'operating the radio',\n",
    "             'drinking',\n",
    "             'reaching behind',\n",
    "             'hair and makeup',\n",
    "             'talking to passenger']\n",
    "    \n",
    "    largest_value = max(prediction[0])\n",
    "    if largest_value > .60 :\n",
    "        max_index = np.argmax(prediction)\n",
    "        result = label[max_index]\n",
    "    elif largest_value < .60:\n",
    "        result = 'Unknown'\n",
    "\n",
    "\n",
    "    return jsonify(result)\n",
    "\n",
    "# ###################################################################################################\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2d6d55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff7b964",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
